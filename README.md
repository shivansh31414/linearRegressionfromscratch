# 📊 Linear Regression from Scratch in Python

This project demonstrates a simple implementation of **Linear Regression** using **NumPy** and **Gradient Descent**. It’s designed to provide a hands-on understanding of the foundational concepts behind supervised learning algorithms—without relying on libraries like Scikit-learn.

## 🚀 Features

- Built from scratch using NumPy
- Step-by-step implementation of Gradient Descent
- Customizable learning rate and iteration count
- Clean class-based structure for `fit()` and `predict()` methods

## 🧠 Concepts Covered

- Hypothesis representation: \( y = wX + b \)
- Cost function (Mean Squared Error)
- Gradient computation for weights and bias
- Parameter updates using learning rate

## 📁 Files

| File                     | Description                            |
|--------------------------|----------------------------------------|
| `linear_regression.ipynb`| Main Colab notebook with implementation|
| `linear_regression.py`   | (Optional) Script version of the notebook |
| `requirements.txt`       | Package dependencies (NumPy, Jupyter)  |
| `sample_data.csv`        | (Optional) Input dataset if applicable |

## 🛠️ How to Use

1. Clone the repo:
   ```bash
   git clone https://github.com/YOUR_USERNAME/linear-regression-scratch.git
   cd linear-regression-scratch
